{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "\n",
    "# Фиксируем сид для NumPy\n",
    "np.random.seed(42)\n",
    "\n",
    "# Фиксируем сид для встроенного модуля random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Распакуем данные в отдельную папку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Path to the ZIP file\n",
    "zip_filepath = './hse-rec-sys-challenge-2024.zip'\n",
    "\n",
    "# Destination folder where the extracted files will be placed\n",
    "destination_folder = 'data'\n",
    "\n",
    "# Ensure that the destination folder exists\n",
    "os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "# Unzip the file to the specified folder\n",
    "with zipfile.ZipFile(zip_filepath, 'r') as zf:\n",
    "    zf.extractall(path=destination_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим на содержимое"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1505</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3669</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>584</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3390</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2885</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0        0     1505       4          0\n",
       "1        0     3669       3          1\n",
       "2        0      584       4          2\n",
       "3        0     3390       3          3\n",
       "4        0     2885       4          4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_df = pd.read_csv('./data/events.csv')\n",
    "events_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1505</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3669</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>584</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3390</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2885</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>0</td>\n",
       "      <td>1124</td>\n",
       "      <td>3</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>0</td>\n",
       "      <td>1809</td>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>0</td>\n",
       "      <td>3602</td>\n",
       "      <td>4</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>0</td>\n",
       "      <td>2924</td>\n",
       "      <td>3</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0</td>\n",
       "      <td>3360</td>\n",
       "      <td>2</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>287 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  item_id  rating  timestamp\n",
       "0          0     1505       4          0\n",
       "1          0     3669       3          1\n",
       "2          0      584       4          2\n",
       "3          0     3390       3          3\n",
       "4          0     2885       4          4\n",
       "..       ...      ...     ...        ...\n",
       "282        0     1124       3        321\n",
       "283        0     1809       4        322\n",
       "284        0     3602       4        323\n",
       "285        0     2924       3        325\n",
       "286        0     3360       2        326\n",
       "\n",
       "[287 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_df[events_df['user_id']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>genre_0</th>\n",
       "      <th>genre_1</th>\n",
       "      <th>genre_2</th>\n",
       "      <th>genre_3</th>\n",
       "      <th>genre_4</th>\n",
       "      <th>genre_5</th>\n",
       "      <th>genre_6</th>\n",
       "      <th>genre_7</th>\n",
       "      <th>genre_8</th>\n",
       "      <th>genre_9</th>\n",
       "      <th>genre_10</th>\n",
       "      <th>genre_11</th>\n",
       "      <th>genre_12</th>\n",
       "      <th>genre_13</th>\n",
       "      <th>genre_14</th>\n",
       "      <th>genre_15</th>\n",
       "      <th>genre_16</th>\n",
       "      <th>genre_17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  genre_0  genre_1  genre_2  genre_3  genre_4  genre_5  genre_6  \\\n",
       "0        0        0        1        0        1        1        0        0   \n",
       "1        1        0        0        0        0        0        0        0   \n",
       "2        2        0        0        0        0        0        0        0   \n",
       "3        3        0        0        0        0        0        0        0   \n",
       "4        4        0        0        0        0        0        0        0   \n",
       "\n",
       "   genre_7  genre_8  genre_9  genre_10  genre_11  genre_12  genre_13  \\\n",
       "0        0        1        0         0         0         0         1   \n",
       "1        1        0        0         0         0         0         0   \n",
       "2        1        0        0         0         0         0         0   \n",
       "3        1        0        0         0         0         0         1   \n",
       "4        1        0        0         0         0         0         0   \n",
       "\n",
       "   genre_14  genre_15  genre_16  genre_17  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features_df = pd.read_csv('./data/item_features.csv')\n",
    "item_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4855</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4065</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3331</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5373</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2032</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  gender  age\n",
       "0     4855       0    1\n",
       "1     4065       1   56\n",
       "2     3331       1   25\n",
       "3     5373       1   45\n",
       "4     2032       1   25"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "user_features_df = pd.read_csv('./data/user_features.csv')\n",
    "user_features_df['gender'] = le.fit_transform(user_features_df['gender'])\n",
    "user_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id              item_id\n",
       "0        0  0 1 2 3 4 5 6 7 8 9\n",
       "1        1  0 1 2 3 4 5 6 7 8 9\n",
       "2        2  0 1 2 3 4 5 6 7 8 9\n",
       "3        3  0 1 2 3 4 5 6 7 8 9\n",
       "4        4  0 1 2 3 4 5 6 7 8 9"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_sample_df = pd.read_csv('./data/submission_sample.csv')\n",
    "submission_sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0 1 2 3 4 5 6 7 8 9\n",
       "1       0 1 2 3 4 5 6 7 8 9\n",
       "2       0 1 2 3 4 5 6 7 8 9\n",
       "3       0 1 2 3 4 5 6 7 8 9\n",
       "4       0 1 2 3 4 5 6 7 8 9\n",
       "               ...         \n",
       "6035    0 1 2 3 4 5 6 7 8 9\n",
       "6036    0 1 2 3 4 5 6 7 8 9\n",
       "6037    0 1 2 3 4 5 6 7 8 9\n",
       "6038    0 1 2 3 4 5 6 7 8 9\n",
       "6039    0 1 2 3 4 5 6 7 8 9\n",
       "Name: item_id, Length: 6040, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_sample_df.item_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разобьем выборку на тренировочную, валидационнную и тестовую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (888109, 4)\n",
      "Test shape: (6040, 4)\n"
     ]
    }
   ],
   "source": [
    "from data_split import *\n",
    "train_df, test_df = split_data_by_user(events_df)\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>0</td>\n",
       "      <td>2924</td>\n",
       "      <td>3</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>0</td>\n",
       "      <td>3602</td>\n",
       "      <td>4</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>0</td>\n",
       "      <td>1809</td>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>0</td>\n",
       "      <td>1124</td>\n",
       "      <td>3</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>0</td>\n",
       "      <td>1792</td>\n",
       "      <td>4</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id  item_id  rating  timestamp\n",
       "285        0     2924       3        325\n",
       "284        0     3602       4        323\n",
       "283        0     1809       4        322\n",
       "282        0     1124       3        321\n",
       "281        0     1792       4        320"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in train_df.columns:\n",
    "    if train_df[column].dtype in ['int64', 'int32']:\n",
    "        train_df[column] = train_df[column].astype('int16')\n",
    "        test_df[column] = test_df[column].astype('int16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Негативное сэмплирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from negative_sampling import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1358</td>\n",
       "      <td>0</td>\n",
       "      <td>2311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1410</td>\n",
       "      <td>0</td>\n",
       "      <td>2311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3197</td>\n",
       "      <td>0</td>\n",
       "      <td>2311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>898</td>\n",
       "      <td>0</td>\n",
       "      <td>2311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>484</td>\n",
       "      <td>0</td>\n",
       "      <td>2311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888104</th>\n",
       "      <td>6039</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888105</th>\n",
       "      <td>6039</td>\n",
       "      <td>2290</td>\n",
       "      <td>0</td>\n",
       "      <td>2311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888106</th>\n",
       "      <td>6039</td>\n",
       "      <td>1837</td>\n",
       "      <td>0</td>\n",
       "      <td>2311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888107</th>\n",
       "      <td>6039</td>\n",
       "      <td>1635</td>\n",
       "      <td>0</td>\n",
       "      <td>2311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888108</th>\n",
       "      <td>6039</td>\n",
       "      <td>2680</td>\n",
       "      <td>0</td>\n",
       "      <td>2311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>888109 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id item_id rating timestamp\n",
       "0            0    1358      0      2311\n",
       "1            0    1410      0      2311\n",
       "2            0    3197      0      2311\n",
       "3            0     898      0      2311\n",
       "4            0     484      0      2311\n",
       "...        ...     ...    ...       ...\n",
       "888104    6039       5      0      2311\n",
       "888105    6039    2290      0      2311\n",
       "888106    6039    1837      0      2311\n",
       "888107    6039    1635      0      2311\n",
       "888108    6039    2680      0      2311\n",
       "\n",
       "[888109 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Применение функции негативного сэмплирования\n",
    "negative_samples_df = negative_sampling(train_df)\n",
    "negative_samples_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1522</td>\n",
       "      <td>3601</td>\n",
       "      <td>0</td>\n",
       "      <td>2311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2543</td>\n",
       "      <td>3068</td>\n",
       "      <td>0</td>\n",
       "      <td>2311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1337</td>\n",
       "      <td>2868</td>\n",
       "      <td>0</td>\n",
       "      <td>2311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3155</td>\n",
       "      <td>3048</td>\n",
       "      <td>0</td>\n",
       "      <td>2311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1453</td>\n",
       "      <td>3156</td>\n",
       "      <td>0</td>\n",
       "      <td>2311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776213</th>\n",
       "      <td>1756</td>\n",
       "      <td>1640</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776214</th>\n",
       "      <td>3548</td>\n",
       "      <td>3296</td>\n",
       "      <td>0</td>\n",
       "      <td>2311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776215</th>\n",
       "      <td>880</td>\n",
       "      <td>1809</td>\n",
       "      <td>4</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776216</th>\n",
       "      <td>4508</td>\n",
       "      <td>578</td>\n",
       "      <td>3</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776217</th>\n",
       "      <td>830</td>\n",
       "      <td>555</td>\n",
       "      <td>3</td>\n",
       "      <td>578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1776218 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id item_id rating timestamp\n",
       "0          1522    3601      0      2311\n",
       "1          2543    3068      0      2311\n",
       "2          1337    2868      0      2311\n",
       "3          3155    3048      0      2311\n",
       "4          1453    3156      0      2311\n",
       "...         ...     ...    ...       ...\n",
       "1776213    1756    1640      3        37\n",
       "1776214    3548    3296      0      2311\n",
       "1776215     880    1809      4       286\n",
       "1776216    4508     578      3        96\n",
       "1776217     830     555      3       578\n",
       "\n",
       "[1776218 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_train_df = pd.concat([train_df, negative_samples_df], ignore_index=True)\n",
    "# перемешиваем датафрейм, чтобы негативные примеры не были все в конце датафрейма\n",
    "combined_train_df = combined_train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "combined_train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавляем фичи из двух других таблиц"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_avg_rating</th>\n",
       "      <th>user_num_ratings</th>\n",
       "      <th>user_avg_rating_genre_0</th>\n",
       "      <th>user_avg_rating_genre_1</th>\n",
       "      <th>user_avg_rating_genre_2</th>\n",
       "      <th>user_avg_rating_genre_3</th>\n",
       "      <th>...</th>\n",
       "      <th>user_avg_rating_genre_11</th>\n",
       "      <th>user_avg_rating_genre_12</th>\n",
       "      <th>user_avg_rating_genre_13</th>\n",
       "      <th>user_avg_rating_genre_14</th>\n",
       "      <th>user_avg_rating_genre_15</th>\n",
       "      <th>user_avg_rating_genre_16</th>\n",
       "      <th>user_avg_rating_genre_17</th>\n",
       "      <th>num_genres</th>\n",
       "      <th>movie_avg_rating</th>\n",
       "      <th>movie_num_ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2924</td>\n",
       "      <td>3</td>\n",
       "      <td>325</td>\n",
       "      <td>3.986014</td>\n",
       "      <td>286</td>\n",
       "      <td>0.328671</td>\n",
       "      <td>0.213287</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.15035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062937</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.188811</td>\n",
       "      <td>0.164336</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.059441</td>\n",
       "      <td>0.013986</td>\n",
       "      <td>1</td>\n",
       "      <td>2.708995</td>\n",
       "      <td>189.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3602</td>\n",
       "      <td>4</td>\n",
       "      <td>323</td>\n",
       "      <td>3.986014</td>\n",
       "      <td>286</td>\n",
       "      <td>0.328671</td>\n",
       "      <td>0.213287</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.15035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062937</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.188811</td>\n",
       "      <td>0.164336</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.059441</td>\n",
       "      <td>0.013986</td>\n",
       "      <td>4</td>\n",
       "      <td>2.735499</td>\n",
       "      <td>431.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1809</td>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>3.986014</td>\n",
       "      <td>286</td>\n",
       "      <td>0.328671</td>\n",
       "      <td>0.213287</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.15035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062937</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.188811</td>\n",
       "      <td>0.164336</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.059441</td>\n",
       "      <td>0.013986</td>\n",
       "      <td>2</td>\n",
       "      <td>3.549116</td>\n",
       "      <td>1018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1124</td>\n",
       "      <td>3</td>\n",
       "      <td>321</td>\n",
       "      <td>3.986014</td>\n",
       "      <td>286</td>\n",
       "      <td>0.328671</td>\n",
       "      <td>0.213287</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.15035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062937</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.188811</td>\n",
       "      <td>0.164336</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.059441</td>\n",
       "      <td>0.013986</td>\n",
       "      <td>2</td>\n",
       "      <td>3.494970</td>\n",
       "      <td>497.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1792</td>\n",
       "      <td>4</td>\n",
       "      <td>320</td>\n",
       "      <td>3.986014</td>\n",
       "      <td>286</td>\n",
       "      <td>0.328671</td>\n",
       "      <td>0.213287</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.15035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062937</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.188811</td>\n",
       "      <td>0.164336</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.059441</td>\n",
       "      <td>0.013986</td>\n",
       "      <td>1</td>\n",
       "      <td>3.677316</td>\n",
       "      <td>626.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp  user_avg_rating  user_num_ratings  \\\n",
       "0        0     2924       3        325         3.986014               286   \n",
       "1        0     3602       4        323         3.986014               286   \n",
       "2        0     1809       4        322         3.986014               286   \n",
       "3        0     1124       3        321         3.986014               286   \n",
       "4        0     1792       4        320         3.986014               286   \n",
       "\n",
       "   user_avg_rating_genre_0  user_avg_rating_genre_1  user_avg_rating_genre_2  \\\n",
       "0                 0.328671                 0.213287                 0.090909   \n",
       "1                 0.328671                 0.213287                 0.090909   \n",
       "2                 0.328671                 0.213287                 0.090909   \n",
       "3                 0.328671                 0.213287                 0.090909   \n",
       "4                 0.328671                 0.213287                 0.090909   \n",
       "\n",
       "   user_avg_rating_genre_3  ...  user_avg_rating_genre_11  \\\n",
       "0                  0.15035  ...                  0.062937   \n",
       "1                  0.15035  ...                  0.062937   \n",
       "2                  0.15035  ...                  0.062937   \n",
       "3                  0.15035  ...                  0.062937   \n",
       "4                  0.15035  ...                  0.062937   \n",
       "\n",
       "   user_avg_rating_genre_12  user_avg_rating_genre_13  \\\n",
       "0                  0.045455                  0.188811   \n",
       "1                  0.045455                  0.188811   \n",
       "2                  0.045455                  0.188811   \n",
       "3                  0.045455                  0.188811   \n",
       "4                  0.045455                  0.188811   \n",
       "\n",
       "   user_avg_rating_genre_14  user_avg_rating_genre_15  \\\n",
       "0                  0.164336                  0.227273   \n",
       "1                  0.164336                  0.227273   \n",
       "2                  0.164336                  0.227273   \n",
       "3                  0.164336                  0.227273   \n",
       "4                  0.164336                  0.227273   \n",
       "\n",
       "   user_avg_rating_genre_16  user_avg_rating_genre_17  num_genres  \\\n",
       "0                  0.059441                  0.013986           1   \n",
       "1                  0.059441                  0.013986           4   \n",
       "2                  0.059441                  0.013986           2   \n",
       "3                  0.059441                  0.013986           2   \n",
       "4                  0.059441                  0.013986           1   \n",
       "\n",
       "   movie_avg_rating  movie_num_ratings  \n",
       "0          2.708995              189.0  \n",
       "1          2.735499              431.0  \n",
       "2          3.549116             1018.0  \n",
       "3          3.494970              497.0  \n",
       "4          3.677316              626.0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from feature_additions import *\n",
    "\n",
    "user_features_from_train = get_user_features_from_train(train_df, item_features_df)\n",
    "item_features_from_train = get_item_features_from_train(train_df, item_features_df)\n",
    "\n",
    "# Присоединение признаков к тестовому набору данных\n",
    "featured_train_df = join_features(train_df, user_features_from_train, item_features_from_train)\n",
    "featured_test_df = join_features(test_df, user_features_from_train, item_features_from_train)\n",
    "\n",
    "# Итоговый тестовый датасет с признаками\n",
    "featured_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функции для классификации фильмов (выставление оценок)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from models.models_to_generate_candidates import *\n",
    "\n",
    "classifiers = {\n",
    "    'LogisticRegression': LogisticRegression(random_state=42),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=42),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Вышка\\FTiAD\\recsys\\RecSysCompetition\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training GradientBoosting\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# у меня обучалось 32 минуты...\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m trained_models \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatured_train_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrating\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifiers\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Вышка\\FTiAD\\recsys\\RecSysCompetition\\models\\models_to_generate_candidates.py:24\u001b[0m, in \u001b[0;36mtrain_models\u001b[1;34m(train_df, target_column, classifiers)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, classifier \u001b[38;5;129;01min\u001b[39;00m classifiers\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m     trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     trained_models[name] \u001b[38;5;241m=\u001b[39m trained_model\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trained_models\n",
      "File \u001b[1;32mc:\\Вышка\\FTiAD\\recsys\\RecSysCompetition\\models\\models_to_generate_candidates.py:12\u001b[0m, in \u001b[0;36mtrain_classifier\u001b[1;34m(train_df, target_column, classifier)\u001b[0m\n\u001b[0;32m      9\u001b[0m y \u001b[38;5;241m=\u001b[39m train_df[target_column]\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Обучаем классификатор\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Вышка\\FTiAD\\recsys\\RecSysCompetition\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Вышка\\FTiAD\\recsys\\RecSysCompetition\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:783\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_state()\n\u001b[0;32m    782\u001b[0m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[1;32m--> 783\u001b[0m n_stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_at_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[0;32m    797\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_stages \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Вышка\\FTiAD\\recsys\\RecSysCompetition\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:879\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    872\u001b[0m         initial_loss \u001b[38;5;241m=\u001b[39m factor \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss(\n\u001b[0;32m    873\u001b[0m             y_true\u001b[38;5;241m=\u001b[39my_oob_masked,\n\u001b[0;32m    874\u001b[0m             raw_prediction\u001b[38;5;241m=\u001b[39mraw_predictions[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    875\u001b[0m             sample_weight\u001b[38;5;241m=\u001b[39msample_weight_oob_masked,\n\u001b[0;32m    876\u001b[0m         )\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[1;32m--> 879\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_csc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_csr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[38;5;66;03m# track loss\u001b[39;00m\n\u001b[0;32m    892\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
      "File \u001b[1;32mc:\\Вышка\\FTiAD\\recsys\\RecSysCompetition\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:496\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n\u001b[0;32m    495\u001b[0m X_for_tree_update \u001b[38;5;241m=\u001b[39m X_csr \u001b[38;5;28;01mif\u001b[39;00m X_csr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[1;32m--> 496\u001b[0m \u001b[43m_update_terminal_regions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_for_tree_update\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mneg_g_view\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;66;03m# add tree to ensemble\u001b[39;00m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[i, k] \u001b[38;5;241m=\u001b[39m tree\n",
      "File \u001b[1;32mc:\\Вышка\\FTiAD\\recsys\\RecSysCompetition\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:256\u001b[0m, in \u001b[0;36m_update_terminal_regions\u001b[1;34m(loss, tree, X, y, neg_gradient, raw_prediction, sample_weight, sample_mask, learning_rate, k)\u001b[0m\n\u001b[0;32m    254\u001b[0m y_ \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mtake(indices, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    255\u001b[0m sw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight[indices]\n\u001b[1;32m--> 256\u001b[0m update \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneg_gradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_prediction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;66;03m# TODO: Multiply here by learning rate instead of everywhere else.\u001b[39;00m\n\u001b[0;32m    259\u001b[0m tree\u001b[38;5;241m.\u001b[39mvalue[leaf, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m update\n",
      "File \u001b[1;32mc:\\Вышка\\FTiAD\\recsys\\RecSysCompetition\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:212\u001b[0m, in \u001b[0;36m_update_terminal_regions.<locals>.compute_update\u001b[1;34m(y_, indices, neg_gradient, raw_prediction, k)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_update\u001b[39m(y_, indices, neg_gradient, raw_prediction, k):\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;66;03m# we take advantage that: y - prob = neg_gradient\u001b[39;00m\n\u001b[1;32m--> 212\u001b[0m     neg_g \u001b[38;5;241m=\u001b[39m \u001b[43mneg_gradient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m     prob \u001b[38;5;241m=\u001b[39m y_ \u001b[38;5;241m-\u001b[39m neg_g\n\u001b[0;32m    214\u001b[0m     K \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mn_classes\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# у меня обучалось 32 минуты...\n",
    "trained_models = train_models(featured_train_df, 'rating', classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "with open('trained_models.pkl', 'wb') as handle:\n",
    "    pickle.dump(trained_models, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('trained_models.pkl', 'rb') as handle:\n",
    "    trained_models = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создадим датасет для фильмов, которые не были просмотрены пользователем (таких пар нет в обучающей выборке)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_non_seen_films_dataset(df):\n",
    "    # Создаем копию featured_train_df, чтобы не изменять оригинальный DataFrame\n",
    "    df = df[['user_id', 'item_id']]\n",
    "    \n",
    "    # Получаем список всех уникальных пользователей и фильмов\n",
    "    unique_users = df[\"user_id\"].unique()\n",
    "    unique_items = df[\"item_id\"].unique()\n",
    "    \n",
    "    # Создаем полный DataFrame с всеми возможными комбинациями пользователей и фильмов\n",
    "    index = pd.MultiIndex.from_product([unique_users, df[\"item_id\"]], names=[\"user_id\", \"item_id\"])\n",
    "    non_seen_films_df = pd.DataFrame(index=index).reset_index()\n",
    "    \n",
    "    # Оставляем только те пары, которых нет в тренировочном наборе\n",
    "    non_seen_films_df = non_seen_films_df[~non_seen_films_df.set_index([\"user_id\", \"item_id\"]).index.isin(df.set_index([\"user_id\", \"item_id\"]).index)]\n",
    "    \n",
    "    return non_seen_films_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in featured_train_df.columns:\n",
    "    if featured_train_df[column].dtype in ['int64', 'int32']:\n",
    "        featured_train_df[column] = featured_train_df[column].astype('int16')\n",
    "        featured_test_df[column] = featured_test_df[column].astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_seen_films_df = create_non_seen_films_dataset(featured_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_seen_films_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теперь воспользуемся нашими обученными модельками, чтобы предсказать рейтинг непросмотренных фильмов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for model in trained_models:\n",
    "    predictions.append(make_predictions(non_seen_films_df, trained_models[model]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_seen_films_with_predictions = non_seen_films_df[['user_id', 'item_id']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, model in enumerate(trained_models):\n",
    "    non_seen_films_with_predictions[model] = predictions[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_seen_films_with_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_seen_films_with_predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теперь добавим фичи другими моделями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = non_seen_films_with_predictions['user_id'].nunique()\n",
    "n_items = non_seen_films_with_predictions['item_id'].nunique()\n",
    "\n",
    "user_item_matrix = np.zeros((n_users, n_items))\n",
    "for line in featured_train_df.itertuples():\n",
    "    user_item_matrix[line[1], line[2]] = line[3]\n",
    "user_item_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_top(user_item_matrix):\n",
    "    \"\"\"\n",
    "    Генерация предсказаний для Top модели \n",
    "    \"\"\"\n",
    "    num_users, num_items = user_item_matrix.shape\n",
    "    predictions = []\n",
    "\n",
    "    # смотрим на популярность фильма\n",
    "    popularity = np.sum(user_item_matrix > 0, axis=0)\n",
    "\n",
    "    # нормализация\n",
    "    min_popularity = np.min(popularity)\n",
    "    max_popularity = np.max(popularity)\n",
    "    normalized_popularity = 5 * (popularity - min_popularity) / (max_popularity - min_popularity)\n",
    "\n",
    "    for user_id in tqdm(range(num_users),desc = 'top_user_score_loading...'):\n",
    "        for item_id in range(num_items):  \n",
    "            # в качестве оценки оценка другими пользователями\n",
    "            predicted_score = normalized_popularity[item_id] \n",
    "            predictions.append({'user': user_id, 'item': item_id, 'topn_score': predicted_score})\n",
    "    return pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topn_scores = predict_top(user_item_matrix)\n",
    "topn_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_lastn(user_item_matrix):\n",
    "    \"\"\"\n",
    "    Генерация предсказаний для LastN модели в формате user | item | score.\n",
    "\n",
    "    \"\"\"\n",
    "    num_users, num_items = user_item_matrix.shape\n",
    "    predictions = []\n",
    "\n",
    "    # Предсказания для каждого пользователя на основе последнего взаимодействия\n",
    "    for user_id in tqdm(range(num_users), desc = 'last_score_prediction...'):\n",
    "        last_items = np.where(user_item_matrix[user_id] > 0)[0]\n",
    "        if len(last_items) > 0:\n",
    "    # последний фильм\n",
    "            last_item_id = last_items[-1]  \n",
    "    # Оценка последнего фильма\n",
    "            last_score = user_item_matrix[user_id, last_item_id]  \n",
    "            for item_id in range(num_items):\n",
    "                predicted_score = last_score  \n",
    "                predictions.append({'user': user_id, 'item': item_id, 'lastn_score': predicted_score})\n",
    "\n",
    "    return pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_scores = predict_lastn(user_item_matrix)\n",
    "last_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_knn_train(user_item_matrix, n_neighbors=10, metric='cosine'):\n",
    "    knn_model = NearestNeighbors(n_neighbors=n_neighbors, metric=metric, algorithm='brute')\n",
    "    knn_model.fit(user_item_matrix)\n",
    "    \n",
    "    return knn_model\n",
    "\n",
    "def predict_for_user(knn_model, user_id, user_item_matrix):\n",
    "    user_data = user_item_matrix[user_id].reshape(1, -1)\n",
    "    distances, indices = knn_model.kneighbors(user_data, return_distance=True)\n",
    "    \n",
    "    return indices, distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_knn(knn_model, user_item_matrix, n_neighbors=10):\n",
    "    \"\"\"\n",
    "    Предсказания для KNN модели в формате user | item | score.\n",
    "    \"\"\"\n",
    "    num_users, num_items = user_item_matrix.shape\n",
    "    predictions = []\n",
    "\n",
    "    for user_id in tqdm(range(num_users),desc = 'user_knn_scores...'):\n",
    "        user_data = user_item_matrix[user_id].reshape(1, -1)\n",
    "        distances, indices = knn_model.kneighbors(user_data, n_neighbors=n_neighbors, return_distance=True)\n",
    "\n",
    "        for item_id in range(num_items):\n",
    "            # нет оценки пользователя\n",
    "            if user_item_matrix[user_id, item_id] == 0:  \n",
    "                neighbor_scores = []\n",
    "                for neighbor in indices.flatten():\n",
    "                    if user_item_matrix[neighbor, item_id] > 0:\n",
    "                        neighbor_scores.append(user_item_matrix[neighbor, item_id])\n",
    "\n",
    "                if neighbor_scores:\n",
    "                    predicted_score = np.mean(neighbor_scores)\n",
    "                    predictions.append({'user': user_id, 'item': item_id, 'knn_score': predicted_score})\n",
    "\n",
    "    return pd.DataFrame(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = simple_knn_train(user_item_matrix, n_neighbors=5)\n",
    "knn_scores = predict_knn(knn_model, user_item_matrix)\n",
    "knn_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_scores = pd.read_csv('knn_scores.csv').iloc[:,1:]\n",
    "knn_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader\n",
    "from surprise import SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "def train_als_with_surprise(user_item_matrix):\n",
    "    \n",
    "    num_users, num_items = user_item_matrix.shape\n",
    "    data = []\n",
    "    \n",
    "    for user_id in tqdm(range(num_users), desc = 'als_user_train'):\n",
    "        for item_id in range(num_items):\n",
    "            if user_item_matrix[user_id, item_id] > 0:\n",
    "                data.append((user_id, item_id, user_item_matrix[user_id, item_id]))\n",
    "    \n",
    "    \n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "    dataset = Dataset.load_from_df(pd.DataFrame(data, columns=['user', 'item', 'rating']), reader)\n",
    "    trainset, testset = train_test_split(dataset, test_size=0.2)\n",
    "    \n",
    "# модель ALS (SVD в Surprise)\n",
    "    als_model = SVD(n_factors=50, n_epochs=20, biased=False) \n",
    "    als_model.fit(trainset)\n",
    "    \n",
    "    return als_model, testset\n",
    "\n",
    "def predict_als_with_surprise(als_model, testset):\n",
    "    predictions = als_model.test(testset)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_model, testset = train_als_with_surprise(user_item_matrix)\n",
    "als_predictions = predict_als_with_surprise(als_model, testset)\n",
    "\n",
    "for pred in als_predictions[:5]:\n",
    "    print(f'User {pred.uid} predicted rating for Item {pred.iid} is {pred.est}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_data = []\n",
    "for pred in als_predictions:\n",
    "    als_data.append({\n",
    "        'user': pred.uid,\n",
    "        'item': pred.iid,\n",
    "        'als_score': pred.est\n",
    "    })\n",
    "\n",
    "als_scores = pd.DataFrame(als_data)\n",
    "als_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = topn_scores.merge(last_scores, on=['user', 'item'], how='left')\n",
    "combined_df = combined_df.merge(knn_scores, on=['user', 'item'], how='left')\n",
    "combined_df = combined_df.merge(als_scores, on=['user', 'item'], how='left')\n",
    "combined_df = combined_df.fillna(0)\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Рейтинг есть! Теперь выберем топ 100 фильмов для каждого пользователя по всем моделям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(user_item_ratings, model_name, n=100):\n",
    "    '''Функция возвращает топ-n фильмов для каждого пользователя'''\n",
    "    \n",
    "    # Сортируем данные по убыванию предсказанной оценки\n",
    "    top_n = user_item_ratings.sort_values(model_name, ascending=False)\n",
    "    \n",
    "    # Оставляем только первые n строк для каждого пользователя\n",
    "    top_n = top_n.groupby('user_id').head(n).reset_index(drop=True)\n",
    "    \n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_top_films_df(non_seen_films_with_predictions, trained_models, n=100):\n",
    "    '''\n",
    "    Функция создает два топа по 100 фильмов на основе двух моделей\n",
    "    '''\n",
    "    \n",
    "    top_films = {}\n",
    "    for model in trained_models:\n",
    "        top_films[model] = get_top_n(\n",
    "            non_seen_films_with_predictions, model, n=n\n",
    "        )\n",
    "    \n",
    "    # Объединяем результаты\n",
    "    result = pd.concat(list(top_films.values()))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_films_df = create_top_films_df(non_seen_films_with_predictions, trained_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_films_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_films_df = top_films_df.drop_duplicates()\n",
    "top_films_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теперь нужно добавить в этот датафрейм фичи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_top_films_df = add_features_to_train_data(\n",
    "    top_films_df, user_features_df, item_features_df)\n",
    "featured_top_films_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кажется финишная прямая... Теперь предскажем топ 10 фильмов для каждого пользователя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Создаем новую колонку с усредненной оценкой от двух моделей\n",
    "featured_top_films_df['average_prediction'] = (sum([featured_top_films_df[model_name] for model_name in trained_models])) / len(trained_models)\n",
    "\n",
    "# Выделяем необходимые признаки для обучения модели\n",
    "X = featured_top_films_df.drop(['average_prediction'], axis=1)\n",
    "y = featured_top_films_df['average_prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем линейную регрессию\n",
    "lr = LinearRegression()\n",
    "lr.fit(X, y)\n",
    "\n",
    "# Применяем обученную модель для предсказаний\n",
    "predictions = lr.predict(X)\n",
    "\n",
    "# Добавляем предсказанные значения в датафрейм\n",
    "featured_top_films_df['final_prediction'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_films = get_top_n(featured_top_films_df, 'final_prediction', n=10)[['user_id', 'item_id']]\n",
    "\n",
    "# Экспортируем результат в CSV-файл\n",
    "top_10_films.to_csv('top_10_films.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_films.user_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Осталось привести к нужному формату сабмита"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_for_submission(df):\n",
    "    # Группируем строки по user_id и соединяем item_id через пробел\n",
    "    submission = (\n",
    "        df\n",
    "        .groupby('user_id')['item_id']\n",
    "        .apply(lambda x: ' '.join(x.astype(str)))\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = format_for_submission(top_10_films)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
