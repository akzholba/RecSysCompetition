{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Распакуем данные в отдельную папку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Path to the ZIP file\n",
    "zip_filepath = './hse-rec-sys-challenge-2024.zip'\n",
    "\n",
    "# Destination folder where the extracted files will be placed\n",
    "destination_folder = 'data'\n",
    "\n",
    "# Ensure that the destination folder exists\n",
    "os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "# Unzip the file to the specified folder\n",
    "with zipfile.ZipFile(zip_filepath, 'r') as zf:\n",
    "    zf.extractall(path=destination_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим на содержимое"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df = pd.read_csv('./data/events.csv')\n",
    "events_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df[events_df['user_id']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features_df = pd.read_csv('./data/item_features.csv')\n",
    "item_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features_df = pd.read_csv('./data/user_features.csv')\n",
    "user_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_sample_df = pd.read_csv('./data/submission_sample.csv')\n",
    "submission_sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_sample_df.item_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разобьем выборку на тренировочную, валидационнную и тестовую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def split_data_by_user(df, test_size=1, val_size=1):\n",
    "    \"\"\"\n",
    "    Функция разделения данных на обучающую, валидационную и тестовую выборки.\n",
    "    \n",
    "    :param df: DataFrame с данными\n",
    "    :param test_size: размер тестового набора (по умолчанию 1)\n",
    "    :param val_size: размер валидационного набора (по умолчанию 1)\n",
    "    :return: три DataFrame: train_df, val_df, test_df\n",
    "    \"\"\"\n",
    "    # Группируем данные по каждому пользователю\n",
    "    grouped = df.groupby('user_id')\n",
    "    \n",
    "    # Список для хранения индексов каждой группы\n",
    "    train_indices = []\n",
    "    val_indices = []\n",
    "    test_indices = []\n",
    "    \n",
    "    # Проходимся по каждой группе\n",
    "    for _, group in grouped:\n",
    "        # Сортируем группу по timestamp\n",
    "        sorted_group = group.sort_values(by='timestamp', ascending=False)\n",
    "        \n",
    "        # Получаем индексы для каждой выборки\n",
    "        test_idx = sorted_group.index[:test_size]\n",
    "        val_idx = sorted_group.index[test_size:test_size + val_size]\n",
    "        train_idx = sorted_group.index[test_size + val_size:]\n",
    "        \n",
    "        # Добавляем индексы в соответствующие списки\n",
    "        train_indices.extend(train_idx)\n",
    "        val_indices.extend(val_idx)\n",
    "        test_indices.extend(test_idx)\n",
    "    \n",
    "    # Формируем DataFrames для каждой выборки\n",
    "    train_df = df.loc[train_indices].copy()\n",
    "    val_df = df.loc[val_indices].copy()\n",
    "    test_df = df.loc[test_indices].copy()\n",
    "    \n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "# Пример использования функции\n",
    "train_df, val_df, test_df = split_data_by_user(events_df)\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Val shape:\", val_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавляем фичи из двух других таблиц"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features_to_train_data(df, user_features_df, item_features_df):\n",
    "    # Слияние с таблицей признаков пользователей\n",
    "    merged_with_users = pd.merge(\n",
    "        left=df,\n",
    "        right=user_features_df,\n",
    "        on=\"user_id\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    \n",
    "    # Слияние с таблицей признаков фильмов\n",
    "    final_merged = pd.merge(\n",
    "        left=merged_with_users,\n",
    "        right=item_features_df,\n",
    "        on=\"item_id\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    \n",
    "    return final_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_train_df = add_features_to_train_data(train_df, user_features_df, item_features_df)\n",
    "featured_val_df = add_features_to_train_data(val_df, user_features_df, item_features_df)\n",
    "featured_test_df = add_features_to_train_data(test_df, user_features_df, item_features_df)\n",
    "\n",
    "featured_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сформируем матрицы \n",
    "\n",
    "размера (n_users, n_items) для обучающего и тестового наборов таким образом, чтобы элемент в ячейке [i, j] отражал оценку i-го пользователя j-му фильму \n",
    "\n",
    "https://makesomecode.me/2018/09/movie-recommendation-system/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = user_features_df['user_id'].nunique()\n",
    "n_items = item_features_df['item_id'].nunique()\n",
    "\n",
    "n_users, n_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrix = np.zeros((n_users, n_items))\n",
    "for line in events_df.itertuples():\n",
    "    data_matrix[line[1], line[2]] = line[3]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "# считаем косинусное расстояние для пользователей и фильмов \n",
    "\n",
    "# (построчно и поколоночно соотвественно).\n",
    "\n",
    "user_similarity = pairwise_distances(data_matrix, metric='cosine')\n",
    "item_similarity = pairwise_distances(data_matrix.T, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
